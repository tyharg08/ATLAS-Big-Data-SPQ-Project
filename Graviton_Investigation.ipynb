{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating the Graviton!\n",
    "This notebook expands on the code in the <a href=\"https://github.com/atlas-outreach-data-tools/notebooks-collection-opendata/blob/master/13-TeV-examples/uproot_python/GravitonAnalysis.ipynb\"> Graviton Analysis</a> notebook by ATLAS, adding new cuts and sections.\n",
    "\n",
    "This analysis loosely follows the search for a ZZ resonance by ATLAS <a href=\"https://link.springer.com/article/10.1140%2Fepjc%2Fs10052-018-5686-3\">found here</a>.\n",
    "\n",
    "This analysis is documented in the paper \"Using ATLAS Data to Investigate Quantum Gravity and the Graviton\" by Anoushka Bhattacharya, Charlie Burgoyne, Daniya Al Kindi and Tyler Hargreaves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='contents'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents: \n",
    "\n",
    "\n",
    "[Preparation](#setup_computer) <br />\n",
    "\n",
    "[1. Importing Packages](#set_up_everytime) <br />\n",
    "\n",
    "[2. Luminosity, fraction and file path settings](#fraction) <br />\n",
    "\n",
    "[3. Dictionary of samples](#samples) <br />\n",
    "\n",
    "[4. Defining functions](#functions) <br />\n",
    "\n",
    "[5. Defining cuts ](#cut) <br />\n",
    "\n",
    "[6. Applying cuts](#apply) <br />\n",
    "\n",
    "[7. Processing](#process) <br />\n",
    "\n",
    "[8. Plotting](#plotting) <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup_computer'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "This code downloads modules needed for the code to run.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "environment_file = \".../environment.yaml\" # add your pathway to your yaml file\n",
    "\n",
    "# Packages you want to install\n",
    "required_packages = ['uproot', 'pandas', 'numpy', 'matplotlib']\n",
    "\n",
    "# Load the environment.yml file\n",
    "with open(environment_file, 'r') as file:\n",
    "    environment_data = yaml.safe_load(file)\n",
    "\n",
    "# Extract dependencies\n",
    "dependencies = environment_data.get('dependencies', [])\n",
    "\n",
    "# Create a list to hold the packages with versions\n",
    "install_packages = []\n",
    "\n",
    "# Find the versions for the required packages\n",
    "for dep in dependencies:\n",
    "    # Check if the dependency is a string (package name)\n",
    "    if isinstance(dep, str):\n",
    "        for package in required_packages:\n",
    "            if dep.startswith(package):\n",
    "                install_packages.append(dep)\n",
    "\n",
    "# Install packages \n",
    "if install_packages:\n",
    "    print(f\"Installing packages: {install_packages}\")\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"--user\"] + install_packages)\n",
    "else:\n",
    "    print(\"No matching packages found in environment.yml.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='set_up_everytime'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing Packages\n",
    "\n",
    "\n",
    "We're going to be using a number of tools to help us:\n",
    "\n",
    "* uproot: lets us read .root files typically used in particle physics into data formats used in python\n",
    "\n",
    "* pandas: lets us store data as dataframes, a format widely used in python\n",
    "\n",
    "* numpy: provides numerical calculations such as histogramming\n",
    "\n",
    "* matplotlib: common tool for making plots, figures, images, visualisations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot # for reading .root files\n",
    "import awkward as ak # added to improve how data is stored\n",
    "import pandas as pd # to store data as dataframe\n",
    "import time # to measure time to analyse\n",
    "import math # for mathematical functions such as square root\n",
    "import numpy as np # for numerical calculations such as histogramming\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "from matplotlib.ticker import AutoMinorLocator,LogLocator,LogFormatterSciNotation # for minor ticks\n",
    "\n",
    "import infofile # local file containing cross-sections, sums of weights, dataset IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fraction'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Luminosity, fraction and filepath settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lumi = 0.5 # fb-1 # data_A only\n",
    "#lumi = 1.9 # fb-1 # data_B only\n",
    "#lumi = 2.9 # fb-1 # data_C only\n",
    "#lumi = 4.7 # fb-1 # data_D only\n",
    "lumi = 10 # fb-1 # data_A,data_B,data_C,data_D\n",
    "\n",
    "fraction = 0.1 # reduce this is you want the code to run quicker\n",
    "                                                                                                                                  \n",
    "#tuple_path = \"Input/4lep/\" # local \n",
    "tuple_path = \"https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/4lep/\" # web address\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='samples'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dictionary of samples\n",
    "\n",
    "This dictionary of samples to process contains prefixes and filepaths so we can make filestrings to access Open Data ATLAS files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = {\n",
    "\n",
    "    'data': {\n",
    "        'list' : ['data_A','data_B','data_C','data_D']\n",
    "    },\n",
    "    \n",
    "    r'$Z,t\\bar{t}$' : { # Z + ttbar\n",
    "        'list' : ['Zee','Zmumu','ttbar_lep'],\n",
    "        'color' : \"#6b59d3\" # purple\n",
    "    },\n",
    "    \n",
    "    r'$t\\bar{t}V$' : { # ttV\n",
    "        'list' : ['ttW','ttee','ttmumu'], # ttW, ttZ(->ee), ttZ(->mm)\n",
    "        'color' : \"#f0f423\" # yellow\n",
    "    },\n",
    "    \n",
    "    'ZZ' : { # ZZ->llll\n",
    "        'list' : ['llll'],\n",
    "        'color' : \"#ff0000\" # red\n",
    "    },\n",
    "    \n",
    "    'Graviton' : {\n",
    "        'list' : ['RS_G_ZZ_llll_c10_m0500'], # mG = 500 GeV\n",
    "        'color' : \"#baff8d\" # green\n",
    "    },\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='functions'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Defining Functions\n",
    "\n",
    "\n",
    "Define function to get data from files\n",
    "\n",
    "The datasets used in this notebook have already been filtered to include at least 4 leptons per event, so that processing is quicker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_files():\n",
    "\n",
    "    data = {} # define empty dictionary to hold dataframes\n",
    "    for s in samples: # loop over samples\n",
    "        print('Processing '+s+' samples') # print which sample\n",
    "        frames = [] # define empty list to hold data\n",
    "        for val in samples[s]['list']: # loop over each file\n",
    "            if s == 'data': prefix = \"Data/\" # Data prefix\n",
    "            else: # MC prefix\n",
    "                prefix = \"MC/mc_\"+str(infofile.infos[val][\"DSID\"])+\".\"\n",
    "            fileString = tuple_path+prefix+val+\".4lep.root\" # file name to open\n",
    "            temp = read_file(fileString,val) # call the function read_file defined below\n",
    "            frames.append(temp) # append dataframe returned from read_file to list of dataframes\n",
    "        data[s] = pd.concat(frames) # dictionary entry is concatenated dataframes\n",
    "    \n",
    "    return data # return dictionary of dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to calculate:\n",
    "* weight of MC event\n",
    "\n",
    "* cross-section weight\n",
    "\n",
    "* 4-lepton invariant mass\n",
    "\n",
    "* transverse momementum in all dimensions\n",
    "\n",
    "* 2-lepton invariant mass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_weight(xsec_weight, mcWeight, pileup, ele, muon, trigger):\n",
    "    return xsec_weight * mcWeight * pileup * ele * muon * trigger\n",
    "\n",
    "\n",
    "def get_xsec_weight(sample):\n",
    "    info = infofile.infos[sample] # open infofile\n",
    "    xsec_weight =(lumi*1000*info[\"xsec\"])/(info[\"sumw\"]*info[\"red_eff\"]) #*1000 to go from fb-1 to pb-1\n",
    "    return xsec_weight # return cross-section weight\n",
    "\n",
    "\n",
    "\n",
    "def calc_mllll(lep_pt, lep_eta, lep_phi, lep_E):\n",
    "    px = lep_pt*np.cos(lep_phi)\n",
    "    py = lep_pt*np.sin(lep_phi)\n",
    "    pz = lep_pt * np.sinh(lep_eta)\n",
    "    E =lep_E\n",
    "\n",
    "    px_sum =ak.sum(px, axis=1)\n",
    "    py_sum = ak.sum(py, axis=1)\n",
    "    pz_sum= ak.sum(pz, axis=1)\n",
    "    E_sum = ak.sum(E, axis=1)\n",
    "\n",
    "    return np.sqrt(E_sum**2 - px_sum**2 - py_sum**2 - pz_sum**2) / 1000  # GeV\n",
    "\n",
    "\n",
    "def calc_p(lep_pt, lep_eta, lep_phi):\n",
    "    px = lep_pt*np.cos(lep_phi)\n",
    "    py = lep_pt*np.sin(lep_phi)\n",
    "    pz = lep_pt * np.sinh(lep_eta)\n",
    "\n",
    "    p=[px, py, pz]\n",
    "\n",
    "    return p\n",
    "\n",
    "def calc_mll(p1, p2, E1, E2): \n",
    "    p_squared= (p1[0] + p2[0])**2 + (p1[1] + p2[1])**2 + (p1[2] + p2[2])**2\n",
    "    E_squared = (E1 + E2)**2\n",
    "\n",
    "    return (np.sqrt(E_squared - p_squared)/1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cut'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Defining cuts\n",
    "\n",
    "This is the basis for which we decide whether to keep or discard events. \n",
    "Returns false if we don't need to make the cut.\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "\n",
    "### a.) Cut on lepton charge\n",
    "\n",
    "Citation: \"selecting two pairs of isolated leptons, each of which is comprised of two leptons with the same flavour and opposite charge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_lep_charge(lep_charge):\n",
    "    try:\n",
    "        charge = lep_charge[0][0] + lep_charge[0][1] + lep_charge[0][2] + lep_charge[0][3]\n",
    "    except:\n",
    "        return True\n",
    "    \n",
    "    if charge == 0:\n",
    "        return False\n",
    "    else: \n",
    "        return True "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.)  Cut on lepton type\n",
    "\n",
    "Citation: \"selecting two pairs of isolated leptons, each of which is comprised of two leptons with the same flavour and opposite charge\" \n",
    "\n",
    "Adapted to include ensuring the pairs of like leptons are also oppositely charged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_lep_type(lep_type, lep_charge):\n",
    "    try:\n",
    "        lep1 = [lep_charge[0][0], lep_type[0][0]]\n",
    "    except:\n",
    "        return True\n",
    "    \n",
    "    \n",
    "    lep2 = [lep_charge[0][1], lep_type[0][1]]\n",
    "    lep3 = [lep_charge[0][2], lep_type[0][2]]\n",
    "    lep4 = [lep_charge[0][3], lep_type[0][3]]\n",
    "\n",
    "    leps=[lep1, lep2, lep3, lep4]\n",
    "    e = 0\n",
    "    m = 0\n",
    "    mcharge = 0\n",
    "    echarge = 0\n",
    "\n",
    "\n",
    "    for lep in leps:\n",
    "        if lep[1]==11:\n",
    "            echarge += lep[0]  \n",
    "            e+=1\n",
    "        elif lep[1]==13:\n",
    "            mcharge += lep[0] \n",
    "            m+=1\n",
    "\n",
    "    condition1 = mcharge + echarge != 0\n",
    "    condition2 = ((e%2) + (m%2) != 0) \n",
    "\n",
    "    return condition1 or condition2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c.)  Cut on 2-lepton invariant mass\n",
    "\n",
    "First the 4 leptons are paired and the pair with a mass closest to 91.2 GeV (the mass of the Z boson) is the lead pair which should have a mass within the range of 76 to 106 GeV. The second pair have a different range: their lower bound is the 4 lepton invariant mass multiplied by 0.74 with 94.4 subtracted from it (0.74 x mllll - 94.4) GeV and the upper bound is 115 GeV. If 4 lepton invariant mass is bigger than 190, it is set equal to 190 or if it is less than 140, it is set equal to 140. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_lep_mass(lep_type, lep_charge, lep_pt, lep_eta, lep_phi,lep_E):\n",
    "    # puts each lepton into an array of its properties\n",
    "    try:\n",
    "        lep1 = [lep_type[0][0], lep_charge[0][0], lep_pt[0][0], lep_eta[0][0], lep_phi[0][0],lep_E[0][0]]\n",
    "    except:\n",
    "        return True\n",
    "    \n",
    "    lep2 = [lep_type[0][1], lep_charge[0][1], lep_pt[0][1], lep_eta[0][1], lep_phi[0][1],lep_E[0][1]]\n",
    "    lep3 = [lep_type[0][2], lep_charge[0][2], lep_pt[0][2], lep_eta[0][2], lep_phi[0][2],lep_E[0][2]]\n",
    "    lep4 = [lep_type[0][3], lep_charge[0][3], lep_pt[0][3], lep_eta[0][3], lep_phi[0][3],lep_E[0][3]]\n",
    "\n",
    "\n",
    "    # sort into positive and negative leptons\n",
    "    pos = []\n",
    "    neg = []\n",
    "    leps=[lep1, lep2, lep3, lep4]\n",
    "\n",
    "    for lep in leps:\n",
    "        if lep[1]==-1:\n",
    "            neg.append(lep)\n",
    "        else:\n",
    "            pos.append(lep)\n",
    "\n",
    "    # p for pos, n for neg, two positives, two negatives, each have their properties\n",
    "    p1_p = calc_p(pos[0][2], pos[0][3], pos[0][4])\n",
    "    p1_pt= pos[0][2]\n",
    "    p1_eta = pos[0][3]\n",
    "    p1_phi = pos[0][4]\n",
    "    p1_E = pos[0][5]\n",
    "\n",
    "    p2_p= calc_p(pos[1][2], pos[1][3], pos[1][4])\n",
    "    p2_pt= pos[1][2]\n",
    "    p2_eta = pos[1][3]\n",
    "    p2_phi = pos[1][4]\n",
    "    p2_E= pos[1][5]\n",
    "\n",
    "    n1_p= calc_p(neg[0][2], neg[0][3], neg[0][4])\n",
    "    n1_pt= neg[0][2]\n",
    "    n1_eta = neg[0][3]\n",
    "    n1_phi = neg[0][4]\n",
    "    n1_E= neg[0][5]\n",
    "\n",
    "    n2_p= calc_p(neg[1][2], neg[1][3], neg[1][4])\n",
    "    n2_pt= neg[1][2]\n",
    "    n2_eta = neg[1][3]\n",
    "    n2_phi = neg[1][4]\n",
    "    n2_E= neg[1][5]\n",
    "    \n",
    "\n",
    "    # calculating 4-lepton invariant mass\n",
    "    pt =[[p1_pt, p2_pt, n1_pt, n2_pt]]\n",
    "    eta = [[p1_eta, p2_eta, n1_eta, n2_eta]]\n",
    "    phi = [[p1_eta, p2_eta, n1_eta, n2_eta]]\n",
    "    E= [[p1_E, p2_E, n1_E, n2_E]]\n",
    "\n",
    "    mllll= calc_mllll(pt,eta,phi,E)\n",
    "\n",
    "    # calculates 2-lepton invariant mass of all different possibilities of pairs, this is equivalent to the mass of a Z boson\n",
    "    masses = [calc_mll(p1_p, n1_p, p1_E, n1_E), calc_mll(p2_p, n2_p, p2_E, n2_E) ,calc_mll(p2_p, n1_p, p2_E, n1_E), calc_mll(p1_p, n2_p, p1_E, n2_E)]\n",
    "\n",
    "    # find mass of the pair closest to 91.2 GeV (the mass of the Z boson)\n",
    "    diff=0\n",
    "    closest=0\n",
    "    lowest_diff= abs(masses[0]-91.2)\n",
    "    for i in range(0,4):\n",
    "        diff= abs(masses[i]-91.2)\n",
    "        if diff<lowest_diff:\n",
    "            lowest_diff=diff\n",
    "            closest=i\n",
    "\n",
    "    # closest pair is Z Boson 1 while the other pair in its set is Z Boson 2\n",
    "    match closest:\n",
    "        case 0:\n",
    "            Z1= masses[0]\n",
    "            Z2= masses[1]\n",
    "        case 1:\n",
    "            Z1= masses[1]\n",
    "            Z2= masses[0]\n",
    "        case 2:\n",
    "            Z1= masses[2]\n",
    "            Z2= masses[3]\n",
    "        case 3:\n",
    "            Z1= masses[3]\n",
    "            Z2= masses[2]\n",
    "\n",
    "    # calculate lower bound for Z2 using mllll\n",
    "    if mllll>190:\n",
    "        mllll=190\n",
    "\n",
    "    if mllll<140:\n",
    "        mllll=140\n",
    "\n",
    "    lower_bound= (0.76*mllll) - 94.4\n",
    "\n",
    "\n",
    "    if Z1>106 or Z1<50 or Z2>115 or Z2<lower_bound:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d.)  Cut on transverse momentum\n",
    "\n",
    "All electrons must have pT > 7 GeV, while muons must have pT > 5 GeV. The lepton with the greatest transverse momentum must have pT > 20 GeV, while the second must have pT > 15 GeV and the third pT > 10 GeV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_lep_Pt(lep_charge, lep_pt, lep_type): \n",
    "    try:\n",
    "        lep1 = [lep_charge[0][0], lep_pt[0][0]/1000, lep_type[0][0]]\n",
    "    except:\n",
    "        return True\n",
    "    \n",
    "    lep2 = [lep_charge[0][1], lep_pt[0][1]/1000, lep_type[0][1]]\n",
    "    lep3 = [lep_charge[0][2], lep_pt[0][2]/1000, lep_type[0][2]]\n",
    "    lep4 = [lep_charge[0][3], lep_pt[0][3]/1000, lep_type[0][3]]\n",
    "\n",
    "    leps=[lep1, lep2, lep3, lep4]\n",
    "\n",
    "    for lep in leps:\n",
    "        if lep[2]==11 and lep[2]<7:\n",
    "            return True\n",
    "        elif lep[2]==13 and lep[2]<5:\n",
    "            return True\n",
    "\n",
    "    p = np.array([lep1[1], lep2[1], lep3[1], lep4[1]])\n",
    "    p= np.sort(p)\n",
    "    \n",
    "    if p[3]>20 and p[2]>15 and p[1]>10:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e.)  Cut on angle seperation\n",
    "\n",
    "The two leptons in a pair must have angular separation, ∆ R, greater than 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_lep_separation(lep_charge, lep_eta, lep_phi):\n",
    "    try:\n",
    "        lep1 = [lep_charge[0][0], lep_eta[0][0], lep_phi[0][0]]\n",
    "    except:\n",
    "        return True\n",
    "    \n",
    "    lep2 = [lep_charge[0][1], lep_eta[0][1], lep_phi[0][1]]\n",
    "    lep3 = [lep_charge[0][2], lep_eta[0][2], lep_phi[0][2]]\n",
    "    lep4 = [lep_charge[0][3], lep_eta[0][3], lep_phi[0][3]]\n",
    "    \n",
    "    pos = []\n",
    "    neg = []\n",
    "    leps=[lep1, lep2, lep3, lep4]\n",
    "\n",
    "\n",
    "    for lep in leps:\n",
    "        if lep[0]==-1:\n",
    "            neg.append(lep)\n",
    "        else:\n",
    "            pos.append(lep)\n",
    "    separation_cuts = []\n",
    "    for pos_lep in pos:\n",
    "        for neg_lep in neg:\n",
    "            delta_eta = pos_lep[1] - neg_lep[1]\n",
    "            delta_phi = pos_lep[2] - neg_lep[2]\n",
    "            separation_cuts.append((math.sqrt(delta_eta**2 + delta_phi**2) < 0.2))\n",
    "    if False in separation_cuts:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='apply'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Applying cuts\n",
    "\n",
    "This function:\n",
    "\n",
    "* Reads the file\n",
    "\n",
    "* Extracts the data we want and organises it in a dataframe\n",
    "\n",
    "* Applies cuts and removes unwanted events from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path, sample):\n",
    "    start = time.time()\n",
    "    print(\"\\tProcessing:\", sample)\n",
    "\n",
    "    tree = uproot.open(path)[\"mini\"]\n",
    "    numevents = tree.num_entries\n",
    "\n",
    "    data_all = []\n",
    "\n",
    "    if 'data' not in sample:\n",
    "        xsec_weight = get_xsec_weight(sample)\n",
    "\n",
    "    for data in tree.iterate([ 'lep_n',\n",
    "        'lep_pt','lep_eta','lep_phi','lep_E',\n",
    "        'lep_charge','lep_type', \n",
    "        'mcWeight','scaleFactor_PILEUP',\n",
    "        'scaleFactor_ELE','scaleFactor_MUON',\n",
    "        'scaleFactor_LepTRIGGER'\n",
    "    ], library=\"ak\", entry_stop=numevents*fraction):\n",
    "\n",
    "        nIn = len(data)\n",
    "        \n",
    "        if 'data' not in sample:\n",
    "            data[\"totalWeight\"] = (\n",
    "                xsec_weight * data[\"mcWeight\"] *\n",
    "                data[\"scaleFactor_PILEUP\"] *\n",
    "                data[\"scaleFactor_ELE\"] *\n",
    "                data[\"scaleFactor_MUON\"] *\n",
    "                data[\"scaleFactor_LepTRIGGER\"]\n",
    "            )\n",
    "\n",
    "        # Apply charge cut\n",
    "        charge_mask = []\n",
    "        for i in range(len(data)):\n",
    "            mask_val1= cut_lep_charge(data[\"lep_charge\"][i:i+1])\n",
    "            charge_mask.append(not(mask_val1))  # Keep events that do NOT fail the cut\n",
    "\n",
    "        charge_mask = ak.Array(charge_mask)\n",
    "        data = data[charge_mask]\n",
    "\n",
    "\n",
    "        # Apply type cut\n",
    "        if len(data)!=0:\n",
    "            type_mask = []\n",
    "            for i in range(len(data)):\n",
    "                mask_val2 = cut_lep_type(data[\"lep_type\"][i:i+1], data[\"lep_charge\"][i:i+1])\n",
    "                type_mask.append(not(mask_val2))  # Keep events that do NOT fail the cut\n",
    "\n",
    "            type_mask = ak.Array(type_mask)\n",
    "            data = data[type_mask]\n",
    "\n",
    "\n",
    "    \n",
    "        # Apply mass cut\n",
    "        if len(data)!=0:\n",
    "            mass_mask = []\n",
    "            for i in range(len(data)):\n",
    "                mask_val= cut_lep_mass( data[\"lep_type\"][i:i+1], data[\"lep_charge\"][i:i+1], data[\"lep_pt\"][i:i+1], data[\"lep_eta\"][i:i+1],data[\"lep_phi\"][i:i+1],data[\"lep_E\"][i:i+1])\n",
    "            \n",
    "                mass_mask.append(not(mask_val))  # Keep events that do NOT fail the cut\n",
    "\n",
    "            mass_mask = ak.Array(mass_mask)\n",
    "            data = data[mass_mask]\n",
    "            \n",
    "        \n",
    "        # Apply transverse momentum cut\n",
    "        if len(data)!=0:\n",
    "            pT_mask = []\n",
    "            for i in range(len(data)):\n",
    "                mask_value = cut_lep_Pt(data[\"lep_charge\"][i:i+1], data[\"lep_pt\"][i:i+1], data[\"lep_type\"][i:i+1])\n",
    "                pT_mask.append(not(mask_value))\n",
    "            pT_mask = ak.Array(pT_mask)\n",
    "            data = data[pT_mask]\n",
    "        \n",
    "        # Apply seperation cut\n",
    "        if len(data)!=0:\n",
    "            sep_mask = []\n",
    "            for i in range(len(data)):\n",
    "                mask_value1 = cut_lep_separation(data[\"lep_charge\"][i:i+1], data[\"lep_eta\"][i:i+1], data[\"lep_phi\"][i:i+1])\n",
    "                sep_mask.append(not(mask_value1))\n",
    "            sep_mask = ak.Array(sep_mask)\n",
    "            data = data[sep_mask]\n",
    "\n",
    "        # Calculate mllll\n",
    "        data[\"mllll\"] = calc_mllll(data[\"lep_pt\"], data[\"lep_eta\"], data[\"lep_phi\"], data[\"lep_E\"])\n",
    "\n",
    "        nOut = len(data)\n",
    "        data_all.append(data)\n",
    "\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"\\t\\t nIn: {nIn},\\t nOut: {nOut}\\t in {round(elapsed,1)}s\")\n",
    "\n",
    "    # Combine all chunks\n",
    "    data_final = ak.concatenate(data_all)\n",
    "\n",
    "    # Convert to pandas for downstream usage\n",
    "    df = ak.to_dataframe(data_final)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='process'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Processing\n",
    "\n",
    "This is where the processing happens (this will take some minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time() # time at start of whole processing\n",
    "data = get_data_from_files() # process all files\n",
    "elapsed = time.time() - start # time after whole processing\n",
    "print(\"Time taken: \"+str(round(elapsed,1))+\"s\") # print total time taken to process every file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='plotting'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Plotting\n",
    "\n",
    "* Define class to display log values\n",
    "\n",
    "* Define function to plot the data \n",
    "\n",
    "* Calls function to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define class to display 1 and 10 normally\n",
    "class CustomTicker(LogFormatterSciNotation): \n",
    "    def __call__(self, x, pos=None): \n",
    "        if x not in [1,10]: # not 1 or 10\n",
    "            return LogFormatterSciNotation.__call__(self,x, pos=None)\n",
    "        else: # 1 or 10\n",
    "            return \"{x:g}\".format(x=x) # standard notation\n",
    "        \n",
    "def plot_data(data):\n",
    "\n",
    "    xmin = 130 # GeV\n",
    "    xmax = 1230 # GeV\n",
    "    step_size = 30 # GeV\n",
    "\n",
    "    bin_edges = np.arange(start=xmin, # The interval includes this value\n",
    "                     stop=xmax+step_size, # The interval doesn't include this value\n",
    "                     step=step_size ) # Spacing between values\n",
    "    bin_centres = np.arange(start=xmin+step_size/2, # The interval includes this value\n",
    "                            stop=xmax+step_size/2, # The interval doesn't include this value\n",
    "                            step=step_size ) # Spacing between values\n",
    "\n",
    "    data_x,_ = np.histogram(data['data']['mllll'], \n",
    "                            bins=bin_edges ) # histogram the data\n",
    "    data_x_errors = np.sqrt( data_x ) # statistical error on the data\n",
    "\n",
    "    signal_x = data['Graviton']['mllll'] # histogram the signal\n",
    "    signal_weights = data['Graviton'].totalWeight # get the weights of the signal events\n",
    "    signal_color = samples['Graviton']['color'] # get the colour for the signal bar\n",
    "\n",
    "    mc_x = [] # define list to hold the Monte Carlo histogram entries\n",
    "    mc_weights = [] # define list to hold the Monte Carlo weights\n",
    "    mc_colors = [] # define list to hold the colors of the Monte Carlo bars\n",
    "    mc_labels = [] # define list to hold the legend labels of the Monte Carlo bars\n",
    "\n",
    "    for s in samples: # loop over samples\n",
    "        if s not in ['data', 'Graviton']: # if not data nor signal\n",
    "            mc_x.append( data[s]['mllll'] ) # append to the list of Monte Carlo histogram entries\n",
    "            mc_weights.append( data[s].totalWeight ) # append to the list of Monte Carlo weights\n",
    "            mc_colors.append( samples[s]['color'] ) # append to the list of Monte Carlo bar colors\n",
    "            mc_labels.append( s ) # append to the list of Monte Carlo legend labels\n",
    "    \n",
    "\n",
    "\n",
    "    # *************\n",
    "    # Main plot \n",
    "    # *************\n",
    "    main_axes = plt.gca() # get current axes\n",
    "    \n",
    "    # plot the data points\n",
    "    main_axes.errorbar(x=bin_centres, y=data_x, yerr=data_x_errors,\n",
    "                       fmt='ko', # 'k' means black and 'o' is for circles \n",
    "                       label='Data') \n",
    "    \n",
    "    # plot the Monte Carlo bars\n",
    "    mc_heights = main_axes.hist(mc_x, bins=bin_edges, \n",
    "                                weights=mc_weights, stacked=True, \n",
    "                                color=mc_colors, label=mc_labels )\n",
    "    \n",
    "    mc_x_tot = mc_heights[0][-1] # stacked background MC y-axis value\n",
    "    \n",
    "    # calculate MC statistical uncertainty: sqrt(sum w^2)\n",
    "    mc_x_err = np.sqrt(np.histogram(np.hstack(mc_x), bins=bin_edges, weights=np.hstack(mc_weights)**2)[0])\n",
    "    \n",
    "    # plot the signal bar\n",
    "    main_axes.hist(signal_x, bins=bin_edges, bottom=mc_x_tot, \n",
    "                   weights=signal_weights, color=signal_color,\n",
    "                   label='Graviton')\n",
    "    \n",
    "    # plot the statistical uncertainty\n",
    "    main_axes.bar(bin_centres, # x\n",
    "                  2*mc_x_err, # heights\n",
    "                  alpha=0.5, # half transparency\n",
    "                  bottom=mc_x_tot-mc_x_err, color='none', \n",
    "                  hatch=\"////\", width=step_size, label='Stat. Unc.' )\n",
    "\n",
    "    # set the x-limit of the main axes\n",
    "    main_axes.set_xlim( left=xmin, right=xmax ) \n",
    "    \n",
    "    # separation of x axis minor ticks\n",
    "    main_axes.xaxis.set_minor_locator( AutoMinorLocator() ) \n",
    "    \n",
    "    # set the axis tick parameters for the main axes\n",
    "    main_axes.tick_params(which='both', # ticks on both x and y axes\n",
    "                          direction='in', # Put ticks inside and outside the axes\n",
    "                          top=True, # draw ticks on the top axis\n",
    "                          right=True ) # draw ticks on right axis\n",
    "    \n",
    "    # x-axis label\n",
    "    main_axes.set_xlabel(r'4-lepton invariant mass $\\mathrm{m_{4l}}$ [GeV]',\n",
    "                        fontsize=13, x=1, horizontalalignment='right' )\n",
    "    \n",
    "    # write y-axis label for main axes\n",
    "    main_axes.set_ylabel('Events / '+str(step_size)+' GeV',\n",
    "                         y=1, horizontalalignment='right') \n",
    "    \n",
    "    # add minor ticks on y-axis for main axes\n",
    "    main_axes.yaxis.set_minor_locator( AutoMinorLocator() ) \n",
    "    \n",
    "    main_axes.set_yscale('log') # set y-scale\n",
    "    smallest_contribution = mc_heights[0][0] # get smallest contribution\n",
    "    smallest_contribution.sort() # sort smallest contribution\n",
    "    bottom = np.amax(data_x)/1000 # set bottom limit on y-axis\n",
    "    top = np.amax(data_x)*100 # set top limit on y-axis\n",
    "    main_axes.set_ylim( bottom=bottom, top=top ) # y-axis limits\n",
    "    main_axes.yaxis.set_major_formatter( CustomTicker() ) \n",
    "    locmin = LogLocator(base=10.0, # log base 10\n",
    "                        subs=(0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9) ) # minor tick every 0.1 \n",
    "    main_axes.yaxis.set_minor_locator( locmin ) # set minor ticks\n",
    "\n",
    "    # Add text 'ATLAS Open Data' on plot\n",
    "    plt.text(0.05, # x\n",
    "             0.93, # y\n",
    "             'ATLAS Open Data', # text\n",
    "             transform=main_axes.transAxes, # coordinate system used is that of main_axes\n",
    "             fontsize=13 ) \n",
    "    \n",
    "    # Add text 'for education' on plot\n",
    "    plt.text(0.05, # x\n",
    "             0.88, # y\n",
    "             'for education', # text\n",
    "             transform=main_axes.transAxes, # coordinate system used is that of main_axes\n",
    "             style='italic',\n",
    "             fontsize=8 ) \n",
    "    \n",
    "    # Add energy and luminosity\n",
    "    lumi_used = str(round(lumi*fraction,2)) # luminosity to write on the plot\n",
    "    plt.text(0.05, # x\n",
    "             0.82, # y\n",
    "             '$\\sqrt{s}$=13 TeV, '+lumi_used+' fb$^{-1}$', # text\n",
    "             transform=main_axes.transAxes ) # coordinate system used is that of main_axes\n",
    "    \n",
    "    # Add a label for the analysis carried out\n",
    "    plt.text(0.05, # x\n",
    "             0.75, # y\n",
    "             r'$G \\rightarrow ZZ \\rightarrow l^+l^-l^+l^-$', # text \n",
    "             transform=main_axes.transAxes ) # coordinate system used is that of main_axes\n",
    "\n",
    "    # draw the legend\n",
    "    main_axes.legend(ncol=2, # 2 columns\n",
    "                     frameon=False ) # no box around the legend\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "plot_data(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
